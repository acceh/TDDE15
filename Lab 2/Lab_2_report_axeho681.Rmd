---
title: "Lab 2"
author: "Axel Holmberg (axeho681)"
date: "9/22/2020"
output: pdf_document
---

```{r Set up, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Task 1

*Build a hidden Markov model (HMM) for the scenario described above.*

```{r task_1, echo=FALSE}
library(HMM)

##### TASK 1 #####

# 10 Different places
states <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
symbol_states <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)

# Equal probability of it moving and staying
transition_probs <- t(matrix(
                   c(0.5, 0.5, 0, 0, 0, 0, 0, 0, 0, 0,
                     0, 0.5, 0.5, 0, 0, 0, 0, 0, 0, 0,
                     0, 0, 0.5, 0.5, 0, 0, 0, 0, 0, 0,
                     0, 0, 0, 0.5, 0.5, 0, 0, 0, 0, 0,
                     0, 0, 0, 0, 0.5, 0.5, 0, 0, 0, 0,
                     0, 0, 0, 0, 0, 0.5, 0.5, 0, 0, 0,
                     0, 0, 0, 0, 0, 0, 0.5, 0.5, 0, 0,
                     0, 0, 0, 0, 0, 0, 0, 0.5, 0.5, 0,
                     0, 0, 0, 0, 0, 0, 0, 0, 0.5, 0.5,
                     0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0.5), 
                     nrow=10, ncol=10))


# Equal probability of it being i-2,i-1,i,i+1 and i+2
emission_probs <-  matrix(
                    c(0.2, 0.2, 0.2, 0, 0, 0, 0, 0, 0.2, 0.2,
                      0.2, 0.2, 0.2, 0.2, 0, 0, 0, 0, 0, 0.2,
                      0.2, 0.2, 0.2, 0.2, 0.2, 0, 0, 0, 0, 0,
                      0, 0.2, 0.2, 0.2, 0.2, 0.2, 0, 0, 0, 0,
                      0, 0, 0.2, 0.2, 0.2, 0.2, 0.2, 0, 0, 0,
                      0, 0, 0, 0.2, 0.2, 0.2, 0.2, 0.2, 0, 0,
                      0, 0, 0, 0, 0.2, 0.2, 0.2, 0.2, 0.2, 0,
                      0, 0, 0, 0, 0, 0.2, 0.2, 0.2, 0.2, 0.2,
                      0.2, 0, 0, 0, 0, 0, 0.2, 0.2, 0.2, 0.2,
                      0.2, 0.2, 0, 0, 0, 0, 0, 0.2, 0.2, 0.2), 
                      nrow=10, ncol=10)


hmm <-
  initHMM(States = states,
          Symbols = symbol_states,
          startProbs = rep(0.1, 10),
          transProbs = transition_probs,
          emissionProbs = emission_probs
          )
print("States:")
states
print("Symbol states:")
symbol_states
print("Transition matrix:")
transition_probs
print("Emission matrix:")
emission_probs
print("Summary of HMM:")
summary(hmm)
```

## Task 2

*Simulate the HMM for 100 time steps.*

```{r task_2, echo=FALSE}
set.seed(12345)
simulated_steps <- simHMM(hmm,100)
print("The observed simulated steps are:")
simulated_steps$observation
```

## Task 3

*Discard the hidden states from the sample obtained above. Use the remaining observations to compute the filtered and smoothed probability distributions for each of the 100 time points. Compute also the most probable path.*

```{r task_3, echo=FALSE}

##### TASK 3 #####

filter_function <- function(alphas) {
  filtered <- matrix(NA,
                     nrow = dim(alphas)[1],
                     ncol = dim(alphas)[2])
  
  for (t in 1:dim(alphas)[2]) {
    filtered[, t] <- alphas[, t] / sum(alphas[, t])
  }
  
  return(filtered)
}


smooth_function <- function(alphas, betas) {
  smoothed <- matrix(NA,
                     nrow = dim(alphas)[1],
                     ncol = dim(alphas)[2])
  
  for (t in 1:dim(alphas)[2]) {
    smoothed[, t] <-
      (alphas[, t] * betas[, t]) / (sum(alphas[, t] * betas[, t]))
  }
  
  return (smoothed)
}


hmm_forward_alpha <-
  exp(forward(hmm = hmm,
              observation = simulated_steps$observation))

hmm_backward_beta <-
  exp(backward(hmm = hmm,
               observation = simulated_steps$observation))

filtered <- filter_function(hmm_forward_alpha)

smoothed <-
  smooth_function(hmm_forward_alpha, hmm_backward_beta)

viterbi <- viterbi(hmm, simulated_steps$observation)

```

The most probable path is:

```{r task_3_2, echo=FALSE}
viterbi
```


## Task 4

*Compute the accuracy of the filtered and smoothed probability distributions, and of the most probable path. That is, compute the percentage of the true hidden states that are guessed by each method.*

```{r task_4_1, echo=FALSE}
accuracy_function <- function(prediction, true) {
  confusion_matrix <- table(prediction, true)
  accuracy <- sum(diag(confusion_matrix))/sum(confusion_matrix)
  return (accuracy)
}

filtered_prediction <- apply(t(filtered), MARGIN = 1, which.max)
smoothed_prediction <- apply(t(smoothed), MARGIN = 1, which.max)

print("Filtered:")
accuracy_function(filtered_prediction, simulated_steps$states)
print("Smoothed:")
accuracy_function(smoothed_prediction, simulated_steps$states)
print("Most probable path:")
accuracy_function(viterbi, simulated_steps$states)
```



## Task 5

*Repeat the previous exercise with different simulated samples. In general, the smoothed distributions should be more accurate than the filtered distributions. Why? In general, the smoothed distributions should be more accurate than the most probable paths, too. Why?*

```{r task_5, echo=FALSE}

##### TASK 5 #####
#Different seed
set.seed(67890)
simulated_steps_seeded <- simHMM(hmm,100)

hmm_forward_alpha_seeded <-
  exp(forward(
    hmm = hmm,
    observation = simulated_steps_seeded$observation
  ))

hmm_backward_beta_seeded <-
  exp( backward(
    hmm = hmm,
    observation = simulated_steps_seeded$observation
  ))

filtered_seeded <- filter_function(hmm_forward_alpha_seeded)

smoothed_seeded <-
  smooth_function(hmm_forward_alpha_seeded, hmm_backward_beta_seeded)

viterbi_seeded <- viterbi(hmm, simulated_steps_seeded$observation)

filtered_prediction_seeded <- apply(t(filtered_seeded), MARGIN = 1, which.max)
smoothed_prediction_seeded <- apply(t(smoothed_seeded), MARGIN = 1, which.max)


accuracy_function(filtered_prediction_seeded, simulated_steps_seeded$states)
accuracy_function(smoothed_prediction_seeded, simulated_steps_seeded$states)
accuracy_function(viterbi_seeded, simulated_steps_seeded$states)
```

The smoothed distribution is more accurate as it takes both $\alpha$ and $\beta$ from the forward and the backward part of the algorithm with the formula $p(z^t|x^{0:T})=(\alpha(z^t)\beta(z^t))/(\sum_zt\alpha(z^t)\beta(z^t))$ compared to the filtering which only takes $\alpha$ in to account $p(z^t|x^{0:t})=\alpha(z^t)/\sum_zt\alpha(z^t)$.

## Task 6

*Is it true that the more observations you have the better you know where the robot is?*

```{r task_6, echo=FALSE}
library(entropy)


simulated_steps_300 <- simHMM(hmm, 300)

hmm_forward_alpha_300 <-
  exp(forward(hmm = hmm,
              observation = simulated_steps_300$observation))

hmm_backward_beta_300 <-
  exp(backward(hmm = hmm,
               observation = simulated_steps_300$observation))

filtered_300 <- filter_function(hmm_forward_alpha)

smoothed_300 <-
  smooth_function(hmm_forward_alpha, hmm_backward_beta)

viterbi_300 <- viterbi(hmm, simulated_steps_300$observation)

filtered_prediction_300 <- apply(t(filtered), MARGIN = 1, which.max)

entropy_100 <- entropy.empirical(filtered_prediction)
entropy_300 <- entropy.empirical(filtered_prediction_300)

```

The entropy for the case with 100 simluated cases is:

```{r task_6_2, echo=FALSE}
entropy_100
```

The entropy for the case with 300 simluated cases is:

```{r task_6_3, echo=FALSE}
entropy_300
```

## Task 7

*Consider any of the samples above of length 100. Compute the probabilities of the hidden states for the time step 101.*

```{r task_7, echo=FALSE}
step_101 <- transition_probs %*% t(filtered)[100, ]
```

The 101st step would be:

```{r task_7_2, echo=FALSE}

step_101
```

\newpage

## Appendix for code

```{r, code=readLines("Lab_2.R"), echo=TRUE, eval=FALSE}

```